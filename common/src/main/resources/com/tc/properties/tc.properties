#
# All content copyright (c) 2003-2008 Terracotta, Inc.,
# except as may otherwise be noted in a separate copyright notice.
# All rights reserved
#

###########################################################################################
#                                                                                         #
#  This is the default TCProperties that can be accessed from DSO code base by calling    #
#  TCProperties.getProperties().getProperty("key") or one of the Typed methods.           #
#                                                                                         #
#  The values here are the default values that can be overridden by placing a             #
#  tc.properties in the base directory where tc.jar resides at runtime.                   #
#                                                                                         #
###########################################################################################

###########################################################################################
# Section                   : L2 Cache Manager Properties
# Description               : This section contains the defaults for the cache manager for the L2
# enabled                   : Enable/disable L2's cache manager
# logging.enabled           : Enable/disable L2's cache manager logging
# leastCount                : Minimum increase in the % usage of memory for starting eviction
#                             once the threshold value specified of memory used is reached
# percentageToEvict         : % of memory to evict once it reaches threshold
# sleepInterval             : Initial sleep time between each cycles of memory usage analysis
# criticalThreshold         : % of memory used after which memory manager will evict aggressively.
#                 Default: 90. However default is set to 70 when offheap enabled, temp swap
#                and less than 2 GB on heap
# threshold                 : % of memory used after which eviction may start
#                 Default: 70. However default is set to 50 when offheap enabled, temp swap
#                and less than 2 GB on heap
# monitorOldGenOnly         : Only monitor old gen objects
# criticalObjectThreshold   : Number of objects that the cache can hold after which the eviction
#                             may start, its highly recommended to not to set it as the size
#                             of the objects is not generally known
###########################################################################################
l2.cachemanager.enabled = true
l2.cachemanager.logging.enabled = false
l2.cachemanager.leastCount = 2
l2.cachemanager.percentageToEvict = 10
l2.cachemanager.sleepInterval = 3000
#l2.cachemanager.criticalThreshold = 90
#l2.cachemanager.threshold = 70
l2.cachemanager.monitorOldGenOnly = true
l2.cachemanager.criticalObjectThreshold = -1

###########################################################################################
# Section                           : L2 Transaction Manager Properties
# logging.enabled                   : Enable/disable L2's tx mgr logging
# logging.verbose                   : Turns on debug loggings for tx mgr
# logging.printStats                : Enables/disables logging for tx stats
# logging.printCommits              : Enables/disables logging for tx commits
# logging.printBroadCastStats       : Enables/disables logging for tx Broadcasts
# passive.throttle.enabled          : Enables/disables throttling of active from Passive when
#                                     the number of pending txns reaches the threshold
# passive.throttle.threshold        : Number of pending transactions after which passive will
#                                     throttle the active
# passive.throttle.maxSleepSeconds  : Sleep time for active when passive throttles it
###########################################################################################
l2.transactionmanager.logging.enabled = false
l2.transactionmanager.logging.verbose = false
l2.transactionmanager.logging.printStats = true
l2.transactionmanager.logging.printCommits = false
l2.transactionmanager.logging.printBroadcastStats = false
l2.transactionmanager.passive.throttle.enabled = true
l2.transactionmanager.passive.throttle.threshold = 20000
l2.transactionmanager.passive.throttle.maxSleepSeconds= 5

###########################################################################################
# Section                       - L2 Object Manager Properties
# Description                   - This section contains the defaults for the object manager of the L2
# cachePolicy : <lru>/<lfu>     - Least Recently Used or Least Frequenctly used
# deleteBatchSize               - Max number of objects deleted in one transaction when
#                                 removing from the object store after a GC
# maxObjectsToCommit            - Max number of Objects commited in one transaction in
#                                 the commit stage and flush stage
# maxObjectsInTxnObjGrouping    - Max number of Objects allowed in the TransactionalObject
#                                 grouping
# maxTxnsInTxnObjectGrouping    - Max number of Transactions allowed in the
#                                 TransactionalObject grouping
# objectrequest.split.size      - Whats the maximum objects that l2 will lookup in one shot
# objectrequest.logging.enabled - Turn on logging to see what object request cache saved
# fault.logging.enabled         - Enables/Disables logging of ManagedObject Faults from
#                                 disk. If enabled, it logs every 1000 faults.
# request.logging.enabled       - Enables/Disables logging of ManagedObject requests from
#                                 clients. If enabled, logs counts of requested instance types
#                                 every 5 seconds.
# flush.logging.enabled         - Enables/Disables logging of ManagedObject flush to
#                                 disk. If enabled, it logs every 1000 faults.
# persistor.logging.enabled     - Enables/Disables logging of commits to disk while running
#                                 in persistent mode.
# loadObjectID.longsPerDiskEntry- Size of long array entry to store object IDs
#                                 in persistent store. One bit for each ID.
# loadObjectID.mapsdatabase.longsPerDiskEntry - Size of long array entry to store existence of
#                                 persistent state. One bit for each ID.
# loadObjectID.checkpoint.maxlimit - Max number of changes to process in one run checkpoint.
# loadObjectID.checkpoint.maxsleep - Max sleep time in milliseconds between checkpoints
# passive.sync.batch.size       - Number of objects in each message that is sent from
#                                 active to passive while synching
# passive.sync.message.maxSizeInMegaBytes - Max Message size of an object sync message to passive
# passive.sync.throttle.timeInMillis - Time to wait before sending the next batch of
#                                 objects to the passive
# l2.objectmanager.passive.sync.throttle.maxPendingMessages - Max object sync messages that can sent
#                  to passive without a ServerTxnAckMessage from the passive.
# dgc.throttle.timeInMillis     - Throttle time for dgc for each cycle for every requestsPerThrottle
#                                 requests for references from object manager
# dgc.throttle.requestsPerThrottle - Number of objects for which object references are requested
#                                    from object manager after which dgc will throttle
# dgc.young.enabled             - Enables/Disables the young gen collector
# dgc.young.frequencyInMillis - The time in millis between each young gen collection.
#                               (default : 1 min, not advisable to run more frequently)
# dgc.faulting.optimization      - This property will not fault in objects that has no references during DGC mark stage
#                                   false - disable faulting optimization
#                                   true - enabled with compressed implementation (spare oids)
# dgc.enterpriseMarkStageInterval - The time between tokens are sent to see if each L2 finished marking (collect/rescue).
#                                   This is for enterprise only.
# dgc.inline.intervalInSeconds - Interval in seconds at which to delete objects removed by inline dgc
# dgc.inline.cleanup.delaySeconds - Seconds to delay the start of the inline dgc reference cleanup
# data.backup.throttle.timeInMillis - time to sleep between copying of each file from the db
#                                     while taking backup
#
###########################################################################################
l2.objectmanager.deleteBatchSize = 5000
l2.objectmanager.cachePolicy = lfu
l2.objectmanager.maxObjectsToCommit = 5000
l2.objectmanager.maxObjectsInTxnObjGrouping = 5000
l2.objectmanager.maxTxnsInTxnObjectGrouping = 500
l2.objectmanager.objectrequest.split.size = 500
l2.objectmanager.objectrequest.logging.enabled = false
l2.objectmanager.fault.logging.enabled = false
l2.objectmanager.request.logging.enabled = false
l2.objectmanager.flush.logging.enabled = false
l2.objectmanager.persistor.logging.enabled = false
l2.objectmanager.loadObjectID.longsPerDiskEntry = 8
l2.objectmanager.loadObjectID.mapsdatabase.longsPerDiskEntry = 1
l2.objectmanager.loadObjectID.checkpoint.maxlimit = -1
l2.objectmanager.loadObjectID.checkpoint.maxsleep = 10000
l2.objectmanager.passive.sync.batch.size = 500
l2.objectmanager.passive.sync.message.maxSizeInMegaBytes = 10
l2.objectmanager.passive.sync.throttle.timeInMillis = 0
l2.objectmanager.passive.sync.throttle.maxPendingMessages = 10
l2.objectmanager.dgc.throttle.timeInMillis = 0
l2.objectmanager.dgc.throttle.requestsPerThrottle = 1000
l2.objectmanager.dgc.young.enabled = false
l2.objectmanager.dgc.young.frequencyInMillis = 180000
l2.objectmanager.dgc.faulting.optimization = true
l2.objectmanager.dgc.enterpriseMarkStageInterval = 1000
l2.objectmanager.dgc.inline.intervalInSeconds = 10
l2.objectmanager.dgc.inline.maxObjects = 10000
l2.objectmanager.dgc.inline.cleanup.delaySeconds = 0
l2.data.backup.throttle.timeInMillis = 0

###########################################################################################
# Section                             : L2 Seda stage properties
# Description                         : This section contains configuration for SEDA stages for L2
# commitstage.threads                 : Number of seda commit stage threads
# faultstage.threads                  : Number of seda fault stage threads
# search.threads                      : Number of seda search stage threads
# query.threads                       : Number of seda query stage threads
# managedobjectrequeststage.threads   : Number of threads for object request seda stage
#                                       (experimental, do not change)
# managedobjectresponsestage.threads  : Number of threads for object response seda stage
# flushstage.threads                  : Number of threads for flusing of objects to disk
#                                       seda stage
# gcdeletestage.threads               : Number of threads for deletetion of objects after
#                                       dgc finishes marking
# stage.sink.capacity                 : Capacity of seda stage queue, Integer.MAX_VALUE if not set
#                    (experimental, do not change)
###########################################################################################
l2.seda.commitstage.threads = 4
#l2.seda.faultstage.threads = 4
#l2.seda.managedobjectrequeststage.threads = 4
#l2.seda.managedobjectresponsestage.threads = 4
#l2.seda.flushstage.threads = 4
l2.seda.search.threads = 4
l2.seda.query.threads = 4
l2.seda.gcdeletestage.threads = 1
l2.seda.stage.sink.capacity = -1
l2.seda.evictionprocessorstage.sink.capacity = 1000
l2.seda.local.cache.transaction.complete.threads = 8
l2.seda.local.cache.transaction.complete.sink.capacity = 5000
l2.seda.local.cache.invalidations.sink.capacity = 5000

###########################################################################################
# Section               : L1 Seda stage properties
# Description           : This section contains configuration for SEDA stages for L1
# stage.sink.capacity   : capacity of L1's seda stage queue, Integer.MAX_VALUE if not set
###########################################################################################
l1.seda.stage.sink.capacity = -1

###########################################################################################
# Section     :  L2 DB Persistence Layer Properties
# Description : This section contains the DB properties thats used in L2
#               For an explanation of these properties look at Berkeley DB documentation.
#               l2.berkeleydb is removed before giving to Berkeley DB JE.
#               je.lock.timeout =  3mins (in microsecs) since je throw Deadlock Exception
#                                  on timeout.
#               je.maxMemoryPercent takes one third of the configured value when in OffHeap
#                  and temp-swap mode.
#        Similarly for Derby, one can give derby properties:
#        e.g. setting derby.storage.pageCacheSize one needs to append "l2.derbydb"
#        like l2.derbydb.derby.storage.pageCacheSize=10000
#               l2.derbydb.derby.storage.pageSize = Size of derby cache pages.
#               l2.derbydb.pageCache.heapUsage = Percentage of heap to be used by derby's cache
#                                                (Has precedence over pageCacheSize)
#               l2.derbydb.derby.storage.pageCacheSize = Number of cache pages for derby to keep in
#                                                        memory.
#               l2.derbydb.logDevice = Set to change the location for derby transaction logs.
#               l2.derbydb.derby.storage.checkpointInterval = Number of bytes before triggering a derby
#                                                             checkpoint.
# factory.name: The factory class for creating database environments.
#        Derby DB: com.tc.objectserver.storage.derby.DerbyDBFactory
#        Berkeley DB: com.tc.objectserver.storage.berkeleydb.BerkeleyDBFactory
###########################################################################################
l2.db.factory.name=com.tc.objectserver.storage.berkeleydb.BerkeleyDBFactory
#l2.db.factory.name=com.tc.objectserver.storage.derby.DerbyDBFactory
l2.berkeleydb.je.lock.timeout=180000000
l2.berkeleydb.je.maxMemoryPercent=25
l2.berkeleydb.je.lock.nLockTables=7
l2.berkeleydb.je.cleaner.bytesInterval=20000000
l2.berkeleydb.je.checkpointer.bytesInterval=100000000
l2.berkeleydb.je.cleaner.detailMaxMemoryPercentage=5
l2.berkeleydb.je.cleaner.lookAheadCacheSize=32768
l2.berkeleydb.je.cleaner.minAge=5
l2.derbydb.derby.storage.pageSize=32768
l2.derbydb.derby.storage.checkpointInterval=134217728
l2.derbydb.derby.maxMemoryPercent=25
l2.derbydb.derby.locks.escalationThreshold=100000
l2.derbydb.derby.locks.waitTimeout=180
l2.derbydb.derby.locks.deadlockTimeout=170
l2.derbydb.derby.storage.logSwitchInterval=134217728
#l2.derbydb.derby.storage.logBufferSize=50331648
#l2.derbydb.derby.storage.pageCacheSize=10000
l2.derbydb.derby.locks.deadlockTrace=true

###########################################################################################
# Section     :  L2 LFU cachepolicy defaults
# Description : If cachePolicy is set to lfu, then these values take effect
#   agingFactor (float)                    - valid values 0 to 1
#   recentlyAccessedIgnorePercentage (int) - valid values 0 - 100
###########################################################################################
l2.lfu.agingFactor = 1
l2.lfu.recentlyAccessedIgnorePercentage = 20

###########################################################################################
# Section :  L2 Bean shell Properties
# Description : Bean shell can be enabled in the server for debugging.
# enabled     :  Enables/disables Beanshell
# port        :   Port number for Beanshell
###########################################################################################
l2.beanshell.enabled = false
l2.beanshell.port = 9929

###########################################################################################
# Section :  Network HA (nha)
# Description : If Networked HA is enabled then these values take effect
#    tcgroupcomm.handshake.timeout  - tc-group-comm handshake timeout milliseconds
#    tcgroupcomm.discovery.interval  - tc-group-comm member discovery interval milliseconds
#    tcgroupcomm.reconnect.enabled  -  Enable L2-L2 reconnect
#    tcgroupcomm.reconnect.timeout  - L2-L2 reconnect windows in milliseconds
#    tcgroupcomm.reconnect.sendqueue.cap - Sendqueue capacity, 0 for Integer.MAX_VALUE
#    tcgroupcomm.reconnect.maxDelayedAcks - At least one ack per maxDelayedAcks messages received
#    tcgroupcomm.reconnect.sendWindow - Max outstanding messages before ack received
#    send.timeout.millis   -  Number of milliseconds to retry sending a message
#    dirtydb.autoDelete    -  Delete old database if any automatically, during passive L2 startup
#    dirtydb.rolling       -  Retain latest rolling number of old databases in the backup directory.
#                                  If 0, all old databases will be retained.
#    autoRestart           -  Automatically restart L2 when it goes down (on few cases only.
#                                  like zap node errors, dirty database startup problems)
###########################################################################################
l2.nha.tcgroupcomm.handshake.timeout = 5000
l2.nha.tcgroupcomm.discovery.interval = 1000
l2.nha.tcgroupcomm.reconnect.enabled = true
l2.nha.tcgroupcomm.reconnect.timeout = 5000
l2.nha.tcgroupcomm.reconnect.sendqueue.cap = 5000
l2.nha.tcgroupcomm.reconnect.maxDelayedAcks = 16
l2.nha.tcgroupcomm.reconnect.sendWindow = 32
l2.nha.send.timeout.millis = 16000
l2.nha.dirtydb.autoDelete = true
l2.nha.dirtydb.rolling = 0
l2.nha.autoRestart = true

###########################################################################################
# Section                   : L2 Server Array Properties
# serverarray.2pc.enabled   : Enables/disables 2 phase commit for enterprise server array
#                             (experimental, do not change)
###########################################################################################
l2.serverarray.2pc.enabled = true

###########################################################################################
# Section : L1 Server Array Properties
# Description :
# objectCreationStrategy     - Supported types round-robin, group-affinity
# roundRobin.startIndex      - The first index to start at for each client. Supports
#                              sequential, random
# roundRobin.coordinatorLoad - Load to apply to coordinator in % compared to other groups
#                              [0-100], 100 being equal load as others
#
# objectCreationStrategy.groupAffinity- Mirror group name as available in tc-config,
#                                      if group-affinity object creation strategy
#                                      is chosen
###########################################################################################
l1.serverarray.objectCreationStrategy = round-robin
l1.serverarray.objectCreationStrategy.roundRobin.startIndex = sequential
l1.serverarray.objectCreationStrategy.groupAffinity.groupName = mirror-group1

###########################################################################################
# Section                       : Misc L2 Properties
# Description                   : Other Miscellaneous L2 Properties
# startuplock.retries.enabled   : If true then L2s will try to lock indefinitely on the data
#                                 directory while starting up
###########################################################################################
l2.startuplock.retries.enabled = false

###########################################################################################
# Section : L1 L2 Config match Property
# Description : This property will check if the client has to match server config
#        i.e. check cluster topology
###########################################################################################
l1.l2.config.validation.enabled = true

###########################################################################################
# Section                   :  L1 JVM Compatibility Properties
# Description               : This section contains the defaults for the JVM compatibility for the L1
# jvm.check.compatibility   : Makes sure that the boot jar with which L1 is running matches
#                             the current VM version running the L1 application
###########################################################################################
l1.jvm.check.compatibility = true

###########################################################################################
# Section             : L1 Integration Modules
# Description         : This section contains the defaults for the L1 integration modules
# repositories        : Comma-separated list of additional module repositories URL's;
#                       if the tc.install-root system property is set, a default repository
#                       of (tc.install-root)/platform/modules will be injected
# default             : Comma-separated list of integration modules that are implicitly
#                       loaded by the L1 in the form specified by the Required-Bundles
#                       OSGI manifest header
# additional          : List of additional integration modules to be started, in the
#                       form specified by the OSGI Required-Bundles manifest header
# tc-version-check    : Off|warn|enforce|strict
# toolkitSearchRange  : Number of minor revision toolkit API increments that the modules
#                       resolver will attempt to locate. For example if toolkit 1.0 is
#                       requested but is not available, then version 1.1 through 1.99 will
#                       be search for (assuming a value of 100 for this property)
###########################################################################################
l1.modules.repositories =
l1.modules.default =
l1.modules.additional =
l1.modules.tc-version-check =
l1.modules.toolkitSearchRange = 100

###########################################################################################
# Section                   : L1 Cache Manager Properties
# Description               : This section contains the defaults for the cache manager for the L1
# enabled                   : Enable/disable L2's cache manager
# logging.enabled           : Enable/disable L2's cache manager logging
# leastCount                : Minimum increase in the % usage of memory for starting eviction
#                             once the threshold value specified of memory used is reached
# percentageToEvict         : % of memory to evict once it reaches threshold
# sleepInterval             : Initial sleep time between each cycles of memory usage analysis
# criticalThreshold         : % of memory used after which memory manager will evict aggressively
# threshold                 : % of memory used after which eviction may start
# monitorOldGenOnly         : Only monitor old gen objects
# criticalObjectThreshold   : Number of objects that the cache can hold after which the eviction
#                             may start, its highly recommended to not to set it as the size
#                             of the objects is not generally known
###########################################################################################
l1.cachemanager.enabled = true
l1.cachemanager.logging.enabled = false
l1.cachemanager.leastCount = 2
l1.cachemanager.percentageToEvict = 10
l1.cachemanager.sleepInterval = 3000
l1.cachemanager.criticalThreshold = 70
l1.cachemanager.threshold = 50
l1.cachemanager.monitorOldGenOnly = true
l1.cachemanager.criticalObjectThreshold = -1

###########################################################################################
#    Section                    :  L1 Transaction Manager Properties
#    Description                : This section contains the defaults for the Transaction manager for the L1
#    logging.enabled            : If true, enables some logging in the transaction manager
#    maxOutstandingBatchSize    : The max number of batches of transaction that each L1
#                                 sends to the L2 at once
#    maxBatchSizeInKiloBytes    : The max size of  batches that are send to the L2 from
#                                 the L1. The units is in Kilobytes
#    maxPendingBatches          : The max number of pending batches the client creates
#                                 before a Batch ack is received from the server, after
#                                 which the client stalls until a Batch ack is received.
#    maxSleepTimeBeforeHalt     : The max time that a user thread will wait for L2 to
#                                 catchup if the L2 is behind applying transactions. This
#                                 time is used before maxPendingBatches is reached. The
#                                 units are in milliseconds
#    completedAckFlushTimeout   : The timeout in milliseconds after which a NullTransaction
#                                 is send to the server if completed txn acks are still pending
#    strings.compress.enabled   : Enables string compression when sending to the L2. There
#                                 is a processing overhead at the L1, but saves network
#                                 bandwidth, reduces memory requirements in the L2 and also
#                                 reduces disk io at the L2.
#    strings.compress.minSize   : Strings with lengths less that this number are not
#                                 compressed
#    folding.enabled            : True/false whether txn folding is enabled. Folding is
#                                 the act of combining similar (but unique) application
#                                 transactions into a single txn (for more optimal processing
#                                 on the server). Only transactions that share common locks
#                                 and objects can be folded.
#    folding.lock.limit         : The maximum number of distinct locks permitted in folded txns
#                                 (0 or less means infinite)
#    folding.object.limit       : Object count threshold for short circuiting txn folding logic
#                                 (0 or less means infinite). If a txn contains more distinct
#                                 than this threshold, there will be no search to determine a
#                                 possible fold target
#    folding.debug              : Enable debug logging for the transaction folder. Use with
#                                 care -- This will cause *lots* of logging to occur
#    timeoutForAckOnExit        : Max wait time in seconds to wait for ACKs before exit.
#                                 value 0 for infinite wait.
###########################################################################################
l1.transactionmanager.logging.enabled = false
l1.transactionmanager.maxOutstandingBatchSize = 4
l1.transactionmanager.maxBatchSizeInKiloBytes = 128
l1.transactionmanager.maxPendingBatches = 88
l1.transactionmanager.maxSleepTimeBeforeHalt = 1024
l1.transactionmanager.completedAckFlushTimeout = 5000
l1.transactionmanager.strings.compress.enabled = true
l1.transactionmanager.strings.compress.logging.enabled = false
l1.transactionmanager.strings.compress.minSize = 512
l1.transactionmanager.folding.enabled = true
l1.transactionmanager.folding.object.limit = 0
l1.transactionmanager.folding.lock.limit = 0
l1.transactionmanager.folding.debug = false
l1.transactionmanager.timeoutForAckOnExit=300

###########################################################################################
# Section                           : L1 Connect Properties
# Description                       : This section contains properties controlling L1 connect feature
# max.connect.retries               : Maximum L2 connection attempts
# connect.versionMatchCheck.enabled : If true, connection is established only when
#                                     L1 and L2 are of the same DSO version
# socket.connect.timeout            : Socket timeout (ms) when connecting to server
# reconnect.waitInterval            : Sleep time (ms) between trying connections to the server
#                                     (values less than 10ms will be set to 10ms)
###########################################################################################
l1.max.connect.retries = -1
l1.connect.versionMatchCheck.enabled = true
l1.socket.connect.timeout=10000
l1.socket.reconnect.waitInterval=1000

###########################################################################################
# Section                           : DSO Cluster Events
# outofbandnotifier.jointime.millis : Clusrter event notification thread join time in millis
###########################################################################################
l1.clusterevents.outofbandnotifier.jointime.millis = 100

tc.transport.handshake.timeout=10000
tc.config.getFromSource.timeout=30000
tc.config.total.timeout=300000

###########################################################################################
# Section           : L1 Reconnect Properties
# Description       : This section contains properties controlling L1 reconnect feature
#
# Note that l1 get these properties from l2, so the local copy of l1 doesn't matter
#
# enabled           : If true, enables l1 reconnect feature (and Once-And-Only-Once protocol)
# timeout.millis    : Number of milliseconds a disconnected L1 is allowed to
# sendqueue.cap     : Sendqueue capacity, 0 for Integer.MAX_VALUE
#                     reconnect to L2 that has not crashed
# maxDelayedAcks    : Max number of messages received for which ack may not be sent
# sendWindow        : Max number of messages that can be sent without getting an ack back

###########################################################################################
l2.l1reconnect.enabled = true
l2.l1reconnect.timeout.millis = 5000
l2.l1reconnect.sendqueue.cap = 5000
l2.l1reconnect.maxDelayedAcks = 16
l2.l1reconnect.sendWindow = 32


###########################################################################################
# Section                   : L1 Object Manager Properties
# Description               : This section contains the defaults for the Object manager for the L1
# remote.maxDNALRUSize      : Count of dnas after which l1s will remove unrequested object
# remote.logging.enabled    : Enable/disable logging of remote object manager
# remote.maxRequestSentImmediately
#                           : Maximum number of requests send immediately after which it will be batched
# remote.batchLookupTimePeriod
#                           : Time Period in millisecond within which requests are batched after sending
#                             maxRequestSentImmediately number of requests.
# objectid.request.size     : Number of object ids requested at once from L2 for creating
#                             new objects
# flush.logging.enabled     : Enable/disable object's flush logging
# fault.logging.enabled     : Enable/disable object's fault logging
###########################################################################################
l1.objectmanager.remote.maxDNALRUSize = 60
l1.objectmanager.remote.logging.enabled = false
l1.objectmanager.remote.maxRequestSentImmediately = 4
l1.objectmanager.remote.batchLookupTimePeriod = 1
l1.objectmanager.objectid.request.size = 50000
l1.objectmanager.flush.logging.enabled = false
l1.objectmanager.fault.logging.enabled = false

###########################################################################################
# Section                   : L1 ServerMap Manager Properties
# remote.maxRequestSentImmediately
#                           : Maximum number of requests send immediately after which it will be batched
# remote.batchLookupTimePeriod
#                           : Time Period in millisecond within which requests are batched after sending
#                             maxRequestSentImmediately number of requests.
###########################################################################################
l1.servermapmanager.remote.maxRequestSentImmediately = 4
l1.servermapmanager.remote.batchLookupTimePeriod = 1

###########################################################################################
# Section                   : L2 ServerMap Properties
# eviction.clientObjectReferences.refresh.interval
#              : ServerMap Eviction Client Object References refresh interval in milliseconds
# eviction.broadcast.maxkeys
#              : ServerMap Eviction Broadcast Message contain max key count entries
###########################################################################################
l2.servermap.eviction.clientObjectReferences.refresh.interval = 60000
l2.servermap.eviction.broadcast.maxkeys = 10000


###########################################################################################
# Section           : L1 Lock Manager Properties
# Description       : This section contains the defaults for the client lock manager for the L1
# striped.count     : Striping count for l1 lock manager
# timeout.interval  : Time after which an unused lock will be a candidate for lock GC
###########################################################################################
l1.lockmanager.striped.count = 128
l1.lockmanager.timeout.interval = 60000
l1.lockmanager.pinning.enabled = true

###########################################################################################
# Section           :  Common Logging properties for both L1 and L2
# Description       : Logging attributes that can be overridden.
# maxBackups        : The maximum number of backup log files to keep
# maxLogFileSize    : The maximum size of a log file in megabytes
# longgc.threshold  : JVM GC taking greater than the time mentioned will be logged
###########################################################################################
logging.maxBackups = 20
logging.maxLogFileSize = 512
logging.longgc.threshold = 8000

###########################################################################################
# Section                             : Common Stage Monitoring properties for both L1 and L2
# Description                         : Stage monitoring can be enabled or disabled for debugging.
# stage.monitor.enabled               : <true/false>    - Enable or Disable Monitoring
# stage.monitor.delay                 : long            - frequency in milliseconds
# bytebuffer.pooling.enabled          : Enable/disable tc byte buffer pooling
# bytebuffer.common.pool.maxcount     : Max size of pool for tc byte buffer
# bytebuffer.threadlocal.pool.maxcount: Thread pool size
###########################################################################################
tc.stage.monitor.enabled = false
tc.stage.monitor.delay = 5000
tc.bytebuffer.pooling.enabled = true
tc.bytebuffer.common.pool.maxcount = 3000
tc.bytebuffer.threadlocal.pool.maxcount = 2000
tc.messages.grouping.enabled = true
tc.messages.grouping.maxSizeKiloBytes = 1024
tc.messages.packup.enabled = true

###########################################################################################
# Section             :  Common property for TC Management MBean
# Description         : TC Management MBeans can be enabled/disabled
# mbeans.enabled      : <true/false>   - All mbeans enabled/disabled
# test.mbeans.enabled : <true/false>   - Test mode mbeans enabled/disabled
###########################################################################################
tc.management.mbeans.enabled = true
tc.management.test.mbeans.enabled = false

###########################################################################################
# Section :  Session properties (applies to all DSO session enabled web apps in this VM)
#    id.length           : The length (in chars) for session identifiers (min 8)
#    serverid            : The server identifier to place in the session ID
#    delimiter           : The delimiter that separates the server ID from the session ID
#    cookie.domain       : Domain value for session cookie
#    cookie.secure       : Force the secure flag in the session cookie (if false then cookie will be set secure for secure(https) requests)
#    cookie.maxage.seconds : The maximum lifetime of the session cookie
#    cookie.name         : Name of the session cookie
#    cookie.enabled      : Enable / disable the use of cookies for session tracking
#    maxidle.seconds     : Session idle timeout in seconds
#    tracking.enabled    : Enable / disable session tracking completely
#    urlrewrite.enabled  : Enable / disable the URL functionality
#    attribute.listeners : Comma separated list of HttpSessionAttributeListener classes
#    listeners           : Comma separated list of HttpSessionListener classes
#    invalidator.sleep   : Sleep time between runs of the session invalidator
#    segments            : Number of striped segments
#
#    request.bench.enabled :   Enable / disable request benchmark logging
#    invalidator.bench.enabled : Enable / disable benchmark logging for session invalidation
#
#    request.tracking           : Enable / disable the stuck request monitor
#    request.tracking.dump      : Enable / disable thread dumping when stuck requests discovered (unix only)
#    request.tracking.interval  : Frequency (ms) of stuck request inspection
#    request.tracking.threshold : Threshold (ms) before requests are considered "stuck"
#    debug.hops                 : Log session hopping (ie. processing of session by more than one VM)
#    debug.hops.interval        : Number of hops between debug printing
#    debug.invalidate           : Log session invalidation
#    statistics.enabled         : Enabled / disable session statistics, made available via JMX
#    vhosts.excluded            : Comma separated list of virtual hosts that should never use Terracotta clustered sessions (tomcat only)
#    debug.sessions             : Output additional debug information when sessions are looked up, created, etc
#    copy.on.read               : For serialized sessions, deserialized attributes on every call to getAttribute()
#    clear.on.access            : For serialized sessions, clear any local materialized/deserialized attributes at the start of each request
#                                 This is a good approximation of a server hop between each request
#    verify.set.attribute       : Snapshot attributes on access/mutation and report if the attribute has changed at the end of the request
###########################################################################################
#session.id.length = 20
#session.serverid =
#session.delimiter =
#session.cookie.domain =
#session.cookie.comment =
#session.cookie.secure = false
#session.cookie.maxage.seconds = -1
#session.cookie.name = JSESSIONID
#session.cookie.path =
#session.cookie.enabled = true
#session.maxidle.seconds = 1800
#session.tracking.enabled = true
#session.urlrewrite.enabled = true
#session.attribute.listeners =
#session.listeners =
#session.segments = 128
session.invalidator.sleep = 300
session.request.bench.enabled = false
session.invalidator.bench.enabled = true
session.request.tracking = false
session.request.tracking.dump = false
session.request.tracking.interval = 2500
session.request.tracking.threshold = 15000
session.debug.hops = false
session.debug.hops.interval = 100
session.debug.invalidate = false
session.statistics.enabled = false
session.vhosts.excluded =
session.debug.sessions = false
session.verify.set.attribute = false


###########################################################################################
# Section :  Memory Monitor
# forcebasic : enable/disable only basic memory monitoring
###########################################################################################
memory.monitor.forcebasic = false


###########################################################################################
# NOTE: All Ehcache properties below refer to the legacy tim-ehcache-1.3 and
# tim-ehcache-1.4 Terracotta Integration Modules.  These properties have no effect on the
# Ehache-Terracotta integration that was added in Ehcache 1.7.
###########################################################################################
#  Section                         : Ehcache
#  clusterAllCacheManagers         : Whether all CacheManager instances are auto-clustered by default,
#                                    i.e. whether static fields CacheManager.ALL_CACHE_MANAGERS and
#                                    CacheManager.singleton will be configured as roots.
#  logging.enabled                 : Enable/disable ehcache logging
#  evictor.logging.enabled         : Enable/disable evictor's logging
#  concurrency                     : Specifies the number of internal segments and gates the maximum
#                                    number of possible concurrent writers to the cache at one time.
#                                    There is memory and management overhead associated with each
#                                    segment. It is best for the hash function used in tim-ehcache
#                                    if the concurrency is a power of 2.
#  evictor.pool.size               : Thread pool size for evictor
#  global.eviction.enable          : Enable/disable global eviction from the cache
#  global.eviction.frequency       : Number of local eviction cycles after which global eviction may
#                                    start
#  global.eviction.segments        : Number of segments of objects for global evictor
#  global.eviction.rest.timeMillis : Sleep time between each segment's eviction
#  readLevel                       : The lock level used during cache read operations. Allowed values are
#                                    READ (default), CONCURRENT, and NO_LOCK.  NO_LOCK is only appropriate
#                                    in the case of read-only or single-threaded cache usage.
#  writeLevel                      : The lock level used during cache write operations.  Allowed values are
#                                    WRITE (default), and CONCURRENT.  WRITE is strongly recommended.
#  storageStrategy.dcv2.localcache.enabled
#                                  : The property enables/disables the local cache when ehcache has a
#                                    storage strategy of DCV2
#  storageStrategy.dcv2.perElementTTITTL.enabled
#                                  : If disabled then custom( or per element) tti/ttl is not considered when serverside
#                                    eviction is performed unless cache level tti/ttl is set. Enabling this has some
#                                    overhead in eviction when cache level tti/ttl is not set, compared when its disabled.
#  storageStrategy.dcv2.evictUnexpiredEntries.enabled
#                                  : When enabled, if maxElementsOnDisk is set and the cache overshoots it, elements will be
#                                    evicted irrespective of whether they are expired or not if enough expired elements
#                                    cant be found.
#  storageStrategy.dcv2.periodicEviction.enabled
#                                  : The property enables/disables the periodic eviction when ehcache has a
#                                    storage strategy of DCV2
#  storageStrategy.dcv2.pinSegments.enabled
#                                  : The property enables/disables the pinning of DCV2 segments in memory
#  storageStrategy.dcv2.eviction.overshoot
#                                  : % overshoot required to trigger capacity eviction
###########################################################################################
ehcache.clusterAllCacheManagers = true
ehcache.logging.enabled = false
ehcache.evictor.logging.enabled = false
ehcache.concurrency = 128
ehcache.evictor.pool.size = 1
ehcache.global.eviction.enable = true
ehcache.global.eviction.frequency = 10
ehcache.global.eviction.segments = 2
ehcache.global.eviction.rest.timeMillis = 10
ehcache.lock.readLevel = READ
ehcache.lock.writeLevel = WRITE
ehcache.storageStrategy.dcv2.localcache.enabled = true
ehcache.storageStrategy.dcv2.perElementTTITTL.enabled = false
ehcache.storageStrategy.dcv2.evictUnexpiredEntries.enabled = true
ehcache.storageStrategy.dcv2.periodicEviction.enabled = true
ehcache.storageStrategy.dcv2.pinSegments.enabled = true
ehcache.storageStrategy.dcv2.eviction.overshoot = 15
#ehcache.invalidator.sleep =


###########################################################################################
# Section                           : Lock statistics
# lock.statistics.enabled           : Enables/disables lock statistics
# l1.lock.statistics.traceDepth     : Depth of locks given to L1s for gathering the statistics
# l1.lock.statistics.gatherInterval : Poll interval for gathering lock statistics
###########################################################################################
lock.statistics.enabled = false
l1.lock.statistics.traceDepth = 0
l1.lock.statistics.gatherInterval = 1

###########################################################################################
# Section           : Greedy Lease Lock
# enabled           : Enable/disable greedy locks grant from L2
# leaseTimeInMillis : Time for which greedy locks are given to L1 if more than one of them
#                     are contending for them
###########################################################################################
l2.lockmanager.greedy.locks.enabled = true
l2.lockmanager.greedy.lease.enabled = true
l2.lockmanager.greedy.lease.leaseTimeInMillis = 50

###########################################################################################
# Section       : TCP Settings
# tcpnodelay    : Enable/disable tcp packet batching
# keepalive     : Enable/disable tcp probe for running/broken connections
###########################################################################################
net.core.tcpnodelay = true
net.core.keepalive = false

###########################################################################################
# Section :  CVT
#   cvt.retriever.notification.interval - Interval between log file messages when the CVT
#                                         retriever is running (in seconds)
#   cvt.statistics.logging.interval     - Interval between logging of statistics data (seconds)
#   cvt.buffer.randomsuffix.enabled     - If true, add a random suffix when a buffer is created
#   cvt.store.randomsuffix.enabled      - If true, add a random suffix when a store is created
#   cvt.rest.interface.enabled          - If false, the REST interface for the CVT will be
#                                        disabled. True by default
#   cvt.client.fail.buffer.open         - If true, always fail the open of the CVT statistics buffer on a client. This is
#                                         supposed to be used by tests. False by default
###########################################################################################
cvt.retriever.notification.interval = 60
cvt.statistics.logging.interval = 900
cvt.buffer.randomsuffix.enabled = false
cvt.store.randomsuffix.enabled = false
cvt.rest.interface.enabled = true
cvt.client.fail.buffer.open = false

###########################################################################################
# Section :  HealthChecker { server(l2)->client(l1), server(l2)->server(l2) (HA), client(l1)->server(l2) }
#  ping.enabled         - If true, healthchecker is enabled.
#  ping.idletime        - Connection idletime (in milliseconds), after which healthchecker
#                         starts its ping test.
#  ping.interval        - The interval (in milliseconds) between healthchecker sending ping
#                         messages to the peer node which doesn't reply to its previous msgs.
#  ping.probes          - Total number of ping messages to be sent to the peer node before
#                         concluding the peer is dead.
#  socketConnect        - If true, apart from above ping-probe cycle, healthcheker does extra
#                         check like socket connect (to detect long GC) to see if the peer has
#                         any traces of life left
#  socketConnectCount   - Max number of successful socket connect that healthcheker
#                         can trust. Beyond which, no socket connects will be
#                         attempted and peer node is tagged as dead.
#  socketConnectTimeout - Socket timeout (integer, in number of ping.interval) when
#                         connecting to the peer node. On timeout, healthchecker
#                         concludes peer node as dead irrespective of previous
#                         successful socket connects.
###########################################################################################
# L2 -> L1  :
# These settings will detect a network disconnect (like a cable pull) in 10 seconds and
#   will allow a 40 second GC in the L1
l2.healthcheck.l1.ping.enabled = true
l2.healthcheck.l1.ping.idletime = 5000
l2.healthcheck.l1.ping.interval = 1000
l2.healthcheck.l1.ping.probes = 3
l2.healthcheck.l1.socketConnect = true
l2.healthcheck.l1.socketConnectTimeout = 5
l2.healthcheck.l1.socketConnectCount = 10

# L2 -> L2  : Networked Active-Passive
# These settings will detect a network disconnect (like a cable pull) in 10 seconds but
#   will allow a 40 second GC in the L2
l2.healthcheck.l2.ping.enabled = true
l2.healthcheck.l2.ping.idletime = 5000
l2.healthcheck.l2.ping.interval = 1000
l2.healthcheck.l2.ping.probes = 3
l2.healthcheck.l2.socketConnect = true
l2.healthcheck.l2.socketConnectTimeout = 5
l2.healthcheck.l2.socketConnectCount = 10

# L1 -> L2  : Health check
# These settings will detect a network disconnect (like a cable pull) in 10 seconds but
#   will allow upto 50 seconds GC in the L2
# L1's CallbackPort Listener can be disabled with the following property.
#   bindPort = -1
l1.healthcheck.l2.bindAddress = 0.0.0.0
l1.healthcheck.l2.bindPort = 0
l1.healthcheck.l2.ping.enabled = true
l1.healthcheck.l2.ping.idletime = 5000
l1.healthcheck.l2.ping.interval = 1000
l1.healthcheck.l2.ping.probes = 3
l1.healthcheck.l2.socketConnect = true
l1.healthcheck.l2.socketConnectTimeout = 5
l1.healthcheck.l2.socketConnectCount = 13

###########################################################################################
# Section :  TCMessage debug monitoring
#   tcm.monitor.enabled - If enabled the count and size of TC messages will be collected and logged
#   tcm.monitor.delay - The delay (in seconds) between reporting to the log
###########################################################################################
tcm.monitor.enabled = false
tcm.monitor.delay = 5

###########################################################################################
# Section :  HTTP
#   http.defaultservlet.enabled - If true, will serve files through embedded HTTP server
#   http.defaultservlet.attribute.aliases - If true, allows aliases like symlinks to be
#                                           followed while serving files
#   http.defaultservlet.attribute.dirallowed - If true, directory listings are returned if
#                                              no welcome file is found
###########################################################################################
http.defaultservlet.enabled = false;
http.defaultservlet.attribute.aliases = false;
http.defaultservlet.attribute.dirallowed = false;

###########################################################################################
# Section :  Remote JMX
#  l2.remotejmx.maxthreads                     - Maximum number of concurrent remote jmx operations permitted
#  l2.remotejmx.idletime                       - Idle timeout (in seconds) for remote jmx processing threads
###########################################################################################
l2.remotejmx.maxthreads = 50
l2.remotejmx.idletime = 5

###########################################################################################
# Section :  Stats Printer
#  stats.printer.intervalInMillis              - Interval at which gathered stats are printed
###########################################################################################
stats.printer.intervalInMillis = 5000

###########################################################################################
# Section :  LicenseManager
# productkey.resource.path                       - path to product key on your classpath
# productkey.path                                - path to product key
###########################################################################################
#productkey.resource.path=
#productkey.path=

###########################################################################################
# Section :  Instrumentation Settings
# instrumentation.finalField.fastRead - Enable/disable `dirty' reading of final fields
###########################################################################################
instrumentation.finalField.fastRead = true

###########################################################################################
# l2.dump.on.exception.timeout - After get an uncaught exception, the server takes a dump. If the
#                 dump doesn't happen within this timeout the server will exit (in seconds).
###########################################################################################
l2.dump.on.exception.timeout = 30

###########################################################################################
# Section :  Dev console Settings
#  console.max.operator.events   -   Number of operator events dev console will show
#                    in the panel before it starts recycling
#   l2.operator.events.store      -   Number of operator events L2s will store to keep the history of the events
#   tc.time.sync.threshold    -   Number of second of tolerable system time difference between
#                   two nodes of cluster beyond which and operator event will be thrown
###########################################################################################
dev.console.max.operator.events = 5000
l2.operator.events.store = 1500
tc.time.sync.threshold = 30

###########################################################################################
# Section :  L1 Shutdown Settings
# l1.shutdown.threadgroup.gracetime - time allowed for termination of all threads in the
#                    TC thread group (in milliseconds).
###########################################################################################
l1.shutdown.threadgroup.gracetime = 30000

###########################################################################################
# Section :  OffHeap Cache Settings
# max.chunk.size             - The Allocator will try to start allocating chunks of this size.
#                                It will then reduce by factor of 2 if it can't allocate this big size.
# min.chunk.size             - The above process of allocation will continue until it reaches this size.
# object.initialDataSize       - initial data size in bytes for ObjectDB
# object.tableSize           - hashmap table size in numbers for ObjectDB
# object.concurrency        - hashmap segments in numbers for ObjectDB
# map.initialDataSize        - initial data size in bytes for MapsDB
# map.tableSize              - hashmap table size in numbers for MapsDB
# map.percentage              - percentage of offheap for mapsDB
# operator.event.generator.sleepInterval - Time interval for generating offheap operator events
# operator.event.generator.threshold    - Percentage offheap used after which a memory offheap event would be thrown
# temp.swap.flush.to.disk.count         - In temp swap with offheap, how many objects to commit in batch while evicting
# temp.swap.throttle.bytes - when running in temp swap, max evicted entries in bytes to hold in memory after which throttle starts
###########################################################################################
l2.offHeapCache.map.concurrency = 1
l2.offHeapCache.map.min.page.size = 4k
l2.offHeapCache.map.max.page.size = 8m
l2.offHeapCache.map.tableSize = 128
l2.offHeapCache.operator.event.generator.sleepInterval = 60000
l2.offHeapCache.operator.event.generator.threshold = 80
l2.offHeapCache.temp.swap.flush.to.disk.count = 5000
l2.offHeapCache.temp.swap.throttle.megaBytes = 100
# l2.offHeapCache.max.chunk.size = 512m
# l2.offHeapCache.min.chunk.size = 32m
# l2.offHeapCache.object.initialDataSize = 1m
# l2.offHeapCache.object.tableSize = 1m
# l2.offHeapCache.object.concurrency = 4k

###########################################################################################
# Section :  Aspectwerkz
# asmclassinfo.ignore.errors     - comma separated list of package names to ignore AsmClassInfo parse errors
###########################################################################################
aw.asmclassinfo.ignore.errors=com.jinspired.

###########################################################################################
# Section :  Search
# query.wait.for.txns     - wait for all current txns in the issuing node to complete before executing queries
# use.commit.thread       - if true, always use a background thread to call lucene commit(). Setting to false will NEVER call commit
#                           and data durability and consistency is no longer guaranteed. 
#							NOTE: if not defined, commit thread will be on for permanent store mode and off otherwise.  
# passive.max.chunk       - maximum chunk size of network message when transferring search index data to passive
# passive.max.pending     - maximum number of un-ACK'd chunks to send to passive at any given time
# lucene.max.buffer       - maxium buffer size (in MB) for each lucene index writer
###########################################################################################
search.query.wait.for.txns = true
# search.use.commit.thread = false
search.passive.max.chunk = 2097152
search.passive.max.pending = 8
search.lucene.use.ram.directory = false
search.lucene.max.buffer = 16.0
search.lucene.mergefactor = 20
search.lucene.maxBufferedDocs = 1000
search.lucene.maxMergeDocs = 10000;

###########################################################################################
# Section : App groups
# appgroups.debug - enable.disable debug logging for app-groups
###########################################################################################
appgroups.debug = false

